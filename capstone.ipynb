{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Schillawski, 10 April 2018\n",
    "\n",
    "Data Science Immersive, General Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:47:35.965871Z",
     "start_time": "2018-04-08T21:46:20.439113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mjschillawski/Google Drive/Data/generalassembly/projects/GitHub Portfolio/capstone_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from ipywidgets import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data From JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/mjschillawski/Desktop/Miscellaneous Data/Yummly28K/'\n",
    "file = 'data_records_27638.txt'\n",
    "\n",
    "data = pd.read_table(path+file,header=None,names=['recipe'],index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/mjschillawski/Desktop/Miscellaneous Data/Yummly28K/metadata27638/'\n",
    "\n",
    "recipes = []\n",
    "\n",
    "for i in data.index:\n",
    "    num = str(i)\n",
    "    while len(num) < 5:\n",
    "        num = '0' + num\n",
    "        \n",
    "    # https://stackoverflow.com/questions/28373282/how-to-read-a-json-dictionary-type-file-with-pandas\n",
    "    with open(path+'meta'+num+'.json') as json_data:\n",
    "        recipe = json.load(json_data)\n",
    "        recipes.append(recipe)\n",
    "\n",
    "recipes = json_normalize(recipes)\n",
    "\n",
    "recipes.to_csv('assets/recipes_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data From CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:49:47.961592Z",
     "start_time": "2018-04-08T21:49:17.088477Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.course</th>\n",
       "      <th>attributes.cuisine</th>\n",
       "      <th>attributes.holiday</th>\n",
       "      <th>attribution.html</th>\n",
       "      <th>attribution.logo</th>\n",
       "      <th>attribution.text</th>\n",
       "      <th>attribution.url</th>\n",
       "      <th>cookTime</th>\n",
       "      <th>cookTimeInSeconds</th>\n",
       "      <th>flavors.Bitter</th>\n",
       "      <th>...</th>\n",
       "      <th>nutritionEstimates</th>\n",
       "      <th>prepTime</th>\n",
       "      <th>prepTimeInSeconds</th>\n",
       "      <th>rating</th>\n",
       "      <th>source.sourceDisplayName</th>\n",
       "      <th>source.sourceRecipeUrl</th>\n",
       "      <th>source.sourceSiteUrl</th>\n",
       "      <th>totalTime</th>\n",
       "      <th>totalTimeInSeconds</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Side Dishes']</td>\n",
       "      <td>['Italian']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href='http://www.yummly.com/recipe/Mushroom...</td>\n",
       "      <td>http://static.yummly.com/api-logo.png</td>\n",
       "      <td>Mushroom Risotto recipes: information powered ...</td>\n",
       "      <td>http://www.yummly.com/recipe/Mushroom-risotto-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Skinnytaste</td>\n",
       "      <td>http://www.skinnytaste.com/2009/10/risotto-is-...</td>\n",
       "      <td>http://www.skinnytaste.com</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>servings: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Main Dishes']</td>\n",
       "      <td>['Barbecue']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href='http://www.yummly.com/recipe/Filipino...</td>\n",
       "      <td>http://static.yummly.com/api-logo.png</td>\n",
       "      <td>Filipino BBQ Pork Skewers recipes: information...</td>\n",
       "      <td>http://www.yummly.com/recipe/Filipino-bbq-pork...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Skinnytaste</td>\n",
       "      <td>http://www.skinnytaste.com/2008/08/filipino-bb...</td>\n",
       "      <td>http://www.skinnytaste.com</td>\n",
       "      <td>40 min</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Main Dishes']</td>\n",
       "      <td>['Italian']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href='http://www.yummly.com/recipe/Mushroom...</td>\n",
       "      <td>http://static.yummly.com/api-logo.png</td>\n",
       "      <td>Mushroom and Roasted Garlic Risotto recipes: i...</td>\n",
       "      <td>http://www.yummly.com/recipe/Mushroom-and-Roas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>MyRecipes</td>\n",
       "      <td>http://www.myrecipes.com/recipe/mushroom-roast...</td>\n",
       "      <td>http://www.myrecipes.com</td>\n",
       "      <td>1 Hr 25 Min</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>Serves 6 (serving size: about 1 cup)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Side Dishes']</td>\n",
       "      <td>['French', 'American']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href='http://www.yummly.com/recipe/Gratin-D...</td>\n",
       "      <td>http://static.yummly.com/api-logo.png</td>\n",
       "      <td>Gratin Dauphinois (Scalloped Potatoes with Che...</td>\n",
       "      <td>http://www.yummly.com/recipe/Gratin-Dauphinois...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>MyRecipes</td>\n",
       "      <td>http://www.myrecipes.com/recipe/gratin-dauphin...</td>\n",
       "      <td>http://www.myrecipes.com</td>\n",
       "      <td>55 min</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>7 servings (serving size: 1 cup)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Main Dishes']</td>\n",
       "      <td>['Barbecue']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href='http://www.yummly.com/recipe/Deliciou...</td>\n",
       "      <td>http://static.yummly.com/api-logo.png</td>\n",
       "      <td>Delicious Grilled Hamburgers recipes: informat...</td>\n",
       "      <td>http://www.yummly.com/recipe/Delicious-Grilled...</td>\n",
       "      <td>10 Min</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...</td>\n",
       "      <td>5 Min</td>\n",
       "      <td>300.0</td>\n",
       "      <td>4</td>\n",
       "      <td>AllRecipes</td>\n",
       "      <td>http://allrecipes.com/Recipe/delicious-grilled...</td>\n",
       "      <td>http://www.allrecipes.com</td>\n",
       "      <td>15 Min</td>\n",
       "      <td>900.0</td>\n",
       "      <td>3 servings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes.course      attributes.cuisine attributes.holiday  \\\n",
       "0   ['Side Dishes']             ['Italian']                NaN   \n",
       "1   ['Main Dishes']            ['Barbecue']                NaN   \n",
       "2   ['Main Dishes']             ['Italian']                NaN   \n",
       "3   ['Side Dishes']  ['French', 'American']                NaN   \n",
       "4   ['Main Dishes']            ['Barbecue']                NaN   \n",
       "\n",
       "                                    attribution.html  \\\n",
       "0  <a href='http://www.yummly.com/recipe/Mushroom...   \n",
       "1  <a href='http://www.yummly.com/recipe/Filipino...   \n",
       "2  <a href='http://www.yummly.com/recipe/Mushroom...   \n",
       "3  <a href='http://www.yummly.com/recipe/Gratin-D...   \n",
       "4  <a href='http://www.yummly.com/recipe/Deliciou...   \n",
       "\n",
       "                        attribution.logo  \\\n",
       "0  http://static.yummly.com/api-logo.png   \n",
       "1  http://static.yummly.com/api-logo.png   \n",
       "2  http://static.yummly.com/api-logo.png   \n",
       "3  http://static.yummly.com/api-logo.png   \n",
       "4  http://static.yummly.com/api-logo.png   \n",
       "\n",
       "                                    attribution.text  \\\n",
       "0  Mushroom Risotto recipes: information powered ...   \n",
       "1  Filipino BBQ Pork Skewers recipes: information...   \n",
       "2  Mushroom and Roasted Garlic Risotto recipes: i...   \n",
       "3  Gratin Dauphinois (Scalloped Potatoes with Che...   \n",
       "4  Delicious Grilled Hamburgers recipes: informat...   \n",
       "\n",
       "                                     attribution.url cookTime  \\\n",
       "0  http://www.yummly.com/recipe/Mushroom-risotto-...      NaN   \n",
       "1  http://www.yummly.com/recipe/Filipino-bbq-pork...      NaN   \n",
       "2  http://www.yummly.com/recipe/Mushroom-and-Roas...      NaN   \n",
       "3  http://www.yummly.com/recipe/Gratin-Dauphinois...      NaN   \n",
       "4  http://www.yummly.com/recipe/Delicious-Grilled...   10 Min   \n",
       "\n",
       "   cookTimeInSeconds  flavors.Bitter                  ...                   \\\n",
       "0                NaN             NaN                  ...                    \n",
       "1                NaN          0.8333                  ...                    \n",
       "2                NaN          1.0000                  ...                    \n",
       "3                NaN          0.6667                  ...                    \n",
       "4              600.0          0.1667                  ...                    \n",
       "\n",
       "                                  nutritionEstimates  prepTime  \\\n",
       "0  [{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...       NaN   \n",
       "1  [{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...       NaN   \n",
       "2  [{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...       NaN   \n",
       "3  [{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...       NaN   \n",
       "4  [{'attribute': 'FAT_KCAL', 'unit': {'name': 'c...     5 Min   \n",
       "\n",
       "   prepTimeInSeconds  rating  source.sourceDisplayName  \\\n",
       "0                NaN       5               Skinnytaste   \n",
       "1                NaN       5               Skinnytaste   \n",
       "2                NaN       3                 MyRecipes   \n",
       "3                NaN       4                 MyRecipes   \n",
       "4              300.0       4                AllRecipes   \n",
       "\n",
       "                              source.sourceRecipeUrl  \\\n",
       "0  http://www.skinnytaste.com/2009/10/risotto-is-...   \n",
       "1  http://www.skinnytaste.com/2008/08/filipino-bb...   \n",
       "2  http://www.myrecipes.com/recipe/mushroom-roast...   \n",
       "3  http://www.myrecipes.com/recipe/gratin-dauphin...   \n",
       "4  http://allrecipes.com/Recipe/delicious-grilled...   \n",
       "\n",
       "         source.sourceSiteUrl    totalTime totalTimeInSeconds  \\\n",
       "0  http://www.skinnytaste.com   30 minutes             1800.0   \n",
       "1  http://www.skinnytaste.com       40 min             2400.0   \n",
       "2    http://www.myrecipes.com  1 Hr 25 Min             5100.0   \n",
       "3    http://www.myrecipes.com       55 min             3300.0   \n",
       "4   http://www.allrecipes.com       15 Min              900.0   \n",
       "\n",
       "                                  yield  \n",
       "0                          servings: 6   \n",
       "1                                   NaN  \n",
       "2  Serves 6 (serving size: about 1 cup)  \n",
       "3      7 servings (serving size: 1 cup)  \n",
       "4                            3 servings  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('assets/recipes_dataset.csv',index_col=0)\n",
    "\n",
    "# transform ingredient field back into list when importing from CSV\n",
    "recipes['ingredientLines'] = recipes['ingredientLines'].apply(\n",
    "    lambda x: [item for item in x.split('\\'') if item not in ('\\,','[',']',', ')])\n",
    "\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features We Care About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:52:32.581300Z",
     "start_time": "2018-04-08T21:52:30.492099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_recipes = recipes[['attributes.course','attributes.cuisine','name','ingredientLines']]\n",
    "short_recipes.to_csv('assets/short_recipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredient Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of components to this. Some are done on an individual, token level. Others are done across ingredients:\n",
    "\n",
    "**Token**:\n",
    "\n",
    "- Strip numbers (quantities)\n",
    "- Strip embedded numbers\n",
    "- Strip common measurements and their abbreviations\n",
    "- Strip punctuation\n",
    "- Strip preparation methods\n",
    "- Create custom stop word dictionary and remove those words from ingredient list\n",
    "\n",
    "**Ingredient-level**:\n",
    "\n",
    "- Inventory a \"typical\" pantry for expected, common items\n",
    "    - Fuzzy match pantry items against the ingredients\n",
    "    - Eliminate those ingredients to reduce recipe complexity\n",
    "- Vectorize ingredients and apply agglomerative clustering\n",
    "    - Measure similiarity/closeness of ingredients based on how they're described\n",
    "    - Replace vectors of ingredients with vectors of clusters in representing recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:52:39.103844Z",
     "start_time": "2018-04-08T21:52:38.835996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multi-threaded\n",
    "def multi_process_ingredients(recipes,join=1,\n",
    "                              nondescript=0,drop_words=None,\n",
    "                              pantry=0,pantry_items=None):\n",
    "    # create the search patterns\n",
    "\n",
    "    # import punctuation characters\n",
    "    # to remove all punctuation\n",
    "    punct = string.punctuation\n",
    "    punct_pattern = r\"[{}]\".format(punct)\n",
    "\n",
    "    # to remove all numbers\n",
    "    number_pattern = r\"\\d+\\s\"\n",
    "\n",
    "    # embedded numbers\n",
    "    embed_num_pattern = r\".\\d+.\"\n",
    "    \n",
    "    # removed prep methods\n",
    "    prep_pattern = r\"[a-z]+ed\"\n",
    "    \n",
    "    # strip pluralization\n",
    "    plural_pattern = r\"s\\s\"\n",
    "    \n",
    "    # strip -ly\n",
    "    ly_pattern = r\"[a-z]+ly\"\n",
    "    \n",
    "    # strip lead number\n",
    "    lead_pattern = r\"\\d+[a-z]+\"\n",
    "    lead_repl = r\"[a-z]+\"\n",
    "    \n",
    "    # trail number\n",
    "    trail_pattern = r\"[a-z]+\\d+\"\n",
    "    trail_repl = r\"[a-z]+\"\n",
    "    \n",
    "    recipes_ingredients = []\n",
    "    ingredients = []\n",
    "\n",
    "    for item in recipes:\n",
    "\n",
    "        # strip punctuation\n",
    "        text = re.sub(punct_pattern,\" \",item)\n",
    "        # strip standalone numbers\n",
    "        text = re.sub(number_pattern,\"\",text)\n",
    "        # strip embedded numbers\n",
    "        text = re.sub(embed_num_pattern,\"\",text)\n",
    "        # strip preparation methods\n",
    "        text = re.sub(prep_pattern,\"\",text)\n",
    "        # strip pluralization\n",
    "        text = re.sub(plural_pattern,\" \",text)\n",
    "        # strip ly\n",
    "        text = re.sub(ly_pattern,\"\",text)\n",
    "        # lead\n",
    "        text = re.sub(lead_pattern,lead_repl,text)\n",
    "        # trail\n",
    "        text = re.sub(trail_pattern,trail_repl,text)\n",
    "\n",
    "        # tokenize\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        processed_text = tokenizer.tokenize(text)\n",
    "\n",
    "        # remove stop words\n",
    "        processed_text = [text.lower() for text in processed_text if text.lower() \n",
    "                          not in stopwords.words('english')]\n",
    "        \n",
    "        # minimum word length\n",
    "        processed_text = [text for text in processed_text if len(text) > 2]\n",
    "\n",
    "        # remove non-descript recipe words\n",
    "        if nondescript == 1 and drop_words != None:\n",
    "            processed_text = [text.lower() for text in processed_text if text.lower()\n",
    "                             not in drop_words]\n",
    "\n",
    "        # append all each list that to describe an ingredient of the recipe\n",
    "        ingredients.append(processed_text)\n",
    "\n",
    "    # joined space-separated strings\n",
    "    # attach all modifiers that describe each ingredient (non-separated)\n",
    "    clean_ingredients = [\" \".join(word) for word in ingredients]\n",
    "    \n",
    "    # remove pantry items\n",
    "    if pantry == 1 and pantry_items != None:\n",
    "        clean_ingredients = [text.lower() for text in clean_ingredients if text.lower() not in pantry_items]\n",
    "\n",
    "    # append all ingredients for each recipe\n",
    "    recipes_ingredients.append(clean_ingredients)   \n",
    "    \n",
    "        \n",
    "    if join == 0:\n",
    "        pass\n",
    "    else:\n",
    "        recipes_ingredients = [\" \".join(ingredient) for ingredient in recipes_ingredients]\n",
    "    \n",
    "    return recipes_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:54:21.607858Z",
     "start_time": "2018-04-08T21:52:41.881823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27638/27638 [01:38<00:00, 279.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27638\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(short_recipes['ingredientLines'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recipes = Parallel(n_jobs=num_cores)(delayed(multi_process_ingredients)(i) for i in inputs)\n",
    "print(len(recipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:54:40.028846Z",
     "start_time": "2018-04-08T21:54:39.969971Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 list of ingredients for each recipe\n",
    "recipes = [\" \".join(recipe) for recipe in recipes]\n",
    "recipes = pd.DataFrame(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:54:43.028285Z",
     "start_time": "2018-04-08T21:54:43.008151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup baby bella mushroom cup arborio rice tsp o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pork country style rib fat cut cubes  cup soy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whole garlic heads tablespoon plu teaspoon ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garlic clove cooking spray potatoe cut inch sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pound lean ground beef tablespoon worcestershi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  cup baby bella mushroom cup arborio rice tsp o...\n",
       "1  pork country style rib fat cut cubes  cup soy ...\n",
       "2  whole garlic heads tablespoon plu teaspoon ext...\n",
       "3  garlic clove cooking spray potatoe cut inch sl...\n",
       "4  pound lean ground beef tablespoon worcestershi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counts for Custom Stopword Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Counts of Words that Describe Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:55:09.455577Z",
     "start_time": "2018-04-08T21:54:49.370595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cup           76725\n",
      "teaspoon      46142\n",
      "tablespoon    40078\n",
      "pepper        26446\n",
      "salt          26439\n",
      "fresh         22512\n",
      "ounce         18745\n",
      "ground        18002\n",
      "oil           17914\n",
      "garlic        13556\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# word counts\n",
    "# get the words that occur most often in recipes\n",
    "# these are candidates for removal in order to simplify the axis that we compare recipes\n",
    "\n",
    "cvec = CountVectorizer(strip_accents=ascii)\n",
    "cvecdata = cvec.fit_transform(recipes[0])\n",
    "\n",
    "cvec_dense  = pd.DataFrame(cvecdata.todense(),\n",
    "             columns=cvec.get_feature_names())\n",
    "\n",
    "word_count = cvec_dense.sum(axis=0)    \n",
    "cw = word_count.sort_values(ascending = False)\n",
    "print(cw[0:10])\n",
    "\n",
    "cw_dict = dict(cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually Evaluate Ingredient Word List to Build Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:55:18.559120Z",
     "start_time": "2018-04-08T21:55:18.432330Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick function to manually evaluate words that ought to be removed\n",
    "# https://stackoverflow.com/questions/5844672/delete-an-item-from-a-dictionary\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "def eval_words(word_list):\n",
    "    keeps = []\n",
    "    nondescript = []\n",
    "    \n",
    "    nondescript_words = [] \n",
    "    keep_words = []\n",
    "    \n",
    "    for key,value in word_list.items():\n",
    "            word_eval = input('Keep {}: {}, y or n?'.format(key,value))\n",
    "        \n",
    "            if word_eval == 'n':\n",
    "                nondescript_words.append(key)\n",
    "            else:\n",
    "                keep_words.append(key)\n",
    "            \n",
    "            remaining_list = removekey(word_list,key)\n",
    "            \n",
    "            if len(nondescript_words) % 100 == 0:\n",
    "                nondescript = nondescript + nondescript_words\n",
    "                keeps = keeps + keep_words\n",
    "                \n",
    "                # empty holding lists\n",
    "                keep_words = []\n",
    "                nondescript_words = []\n",
    "                \n",
    "                prompt_continue = input('Continue: yes or no?')\n",
    "                if prompt_continue == \"yes\":\n",
    "                    pass\n",
    "                else:\n",
    "                    # export lists as pickles for recovery\n",
    "                    # store outside the environment to limit reprocessing\n",
    "                    words_lists = (keeps,nondescript,remaining_list)\n",
    "                    names = (\"keeps\",\"nondescript\",\"remaining\")\n",
    "                    for index,word in enumerate(words_lists):\n",
    "                        with open(\"assets/\"+names[index]+\".pickle\",\"wb\") as file:\n",
    "                            pickle.dump(word,file)\n",
    "                    return keeps, nondescript,remaining_list\n",
    "    \n",
    "    # export word lists for recovery\n",
    "    # so we don't have to do this multiple times\n",
    "    words_lists = (keeps,nondescript,remaining_list)\n",
    "    names = (\"keeps\",\"nondescript\",\"remaining\")\n",
    "    for index,word in enumerate(words_lists):\n",
    "        with open(\"assets/\"+names[index]+\".pickle\",\"wb\") as file:\n",
    "            pickle.dump(word,file)\n",
    "    \n",
    "    return keep_words, nondescript_words, remaining_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pickled Keep/Drop Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:55:43.551474Z",
     "start_time": "2018-04-08T21:55:42.919988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in pickled results\n",
    "keep_list = []\n",
    "drop_list = []\n",
    "\n",
    "names = (\"_keeps\",\"_nondescript\")\n",
    "for name in names:\n",
    "    for index in range(6):\n",
    "        with open(\"assets/\"+str(index)+name+\".pickle\",'rb') as file_handle:\n",
    "            if name == \"_keeps\":\n",
    "                keep_list = keep_list + pickle.load(file_handle)\n",
    "            elif name == \"_nondescript\":\n",
    "                drop_list = drop_list + pickle.load(file_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Human Errors in Keep/Drop Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:55:45.363509Z",
     "start_time": "2018-04-08T21:55:45.223785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice added to drop_list\n",
      "block added to drop_list\n",
      "dipping added to drop_list\n",
      "stems added to drop_list\n",
      "liter added to drop_list\n",
      "pestle added to drop_list\n",
      "2lb added to drop_list\n",
      "pad added to keep list\n",
      "addition added to drop_list\n",
      "paleo added to drop_list\n",
      "smaller added to drop_list\n",
      "teaspoons added to drop_list\n",
      "gf added to drop_list\n",
      "meatles added to drop_list\n",
      "anytime added to drop_list\n",
      "xe4utet added to drop_list\n",
      "almond added to keep list\n",
      "scallions added to keep list\n",
      "evoo added to keep list\n",
      "wing added to keep list\n",
      "non added to keep list\n",
      "meal added to keep list\n",
      "gala added to keep list\n",
      "escarole added to keep list\n",
      "nectarine added to keep list\n",
      "stuffing added to keep list\n",
      "ganache added to keep list\n",
      "speck added to keep list\n",
      "hefe added to keep list\n",
      "champignon added to keep list\n",
      "silver added to keep list\n",
      "blade added to keep list\n",
      "kabocha added to keep list\n",
      "goudak added to keep list\n",
      "lindt added to keep list\n",
      "quorn added to keep list\n",
      "choi added to keep list\n",
      "! evoki not found on either list ! You misspelled target word\n",
      "aioli added to keep list\n",
      "broil added to keep list\n",
      "drumette added to keep list\n",
      "tex added to keep list\n",
      "! massamon not found on either list ! You misspelled target word\n",
      "pao added to keep list\n",
      "steamer added to keep list\n",
      "dandelion added to keep list\n",
      "bonnet added to keep list\n",
      "rapini added to keep list\n",
      "cakes added to keep list\n",
      "! yucatero not found on either list ! You misspelled target word\n",
      "cheek added to keep list\n",
      "latin added to keep list\n",
      "jimmy added to keep list\n",
      "quahog added to keep list\n",
      "cone added to keep list\n",
      "durum added to keep list\n",
      "cornichons added to keep list\n",
      "banh added to keep list\n",
      "fryers added to keep list\n",
      "quantity added to drop_list\n",
      "5tbsp added to drop_list\n",
      "llime added to keep list\n",
      "chopping added to drop_list\n",
      "spam added to keep list\n",
      "ink added to keep list\n",
      "plant added to keep list\n",
      "triangular added to drop_list\n",
      "valencia added to keep list\n",
      "tubetti added to keep list\n",
      "tubettini added to drop_list\n",
      "cavatelli added to keep list\n",
      "perhap added to drop_list\n",
      "livers added to keep list\n",
      "bee added to keep list\n",
      "tartine added to keep list\n",
      "teacup added to drop_list\n",
      "barlett added to keep list\n",
      "maker added to keep list\n",
      "xlour added to keep list\n",
      "jell added to keep list\n",
      "fat added to drop_list\n",
      "free added to drop_list\n",
      "package added to drop_list\n"
     ]
    }
   ],
   "source": [
    "# fix human error from ingredient classifications\n",
    "\n",
    "misclassed_words = ['dice','block','dipping','stems','liter','pestle','2lb','pad','addition','paleo',\n",
    "                    'smaller','teaspoons','gf','meatles','anytime','xe4utet','almond','scallions',\n",
    "                    'evoo','wing','non','meal','gala','escarole','nectarine','stuffing','ganache',\n",
    "                    'speck','hefe','champignon','silver','blade','kabocha','goudak','lindt','quorn',\n",
    "                    'choi','evoki','aioli','broil','drumette','tex','massamon','pao','steamer','dandelion',\n",
    "                    'bonnet','rapini','cakes','yucatero','cheek','latin','jimmy','quahog','cone','durum',\n",
    "                    'cornichons','banh','fryers','quantity','5tbsp','llime','chopping','spam','ink','plant',\n",
    "                    'triangular','valencia','tubetti','tubettini','cavatelli','perhap','livers','bee',\n",
    "                    'tartine','teacup','barlett','maker','xlour','jell','fat','free','package'\n",
    "                   ]\n",
    "\n",
    "for word in misclassed_words:\n",
    "    if word in keep_list and word not in drop_list:\n",
    "        drop_list.append(word)\n",
    "        keep_list.remove(word)\n",
    "        print('{} added to drop_list'.format(word))\n",
    "    elif word in drop_list and word not in keep_list:\n",
    "        keep_list.append(word)\n",
    "        drop_list.remove(word)\n",
    "        print('{} added to keep list'.format(word))\n",
    "    elif word in drop_list and word in keep_list:\n",
    "        print('! {} found on both lists !')\n",
    "    elif word not in drop_list and word not in keep_list:\n",
    "        print('! {} not found on either list ! You misspelled target word'.format(word))\n",
    "    else:\n",
    "        print('! Bigger problems !')\n",
    "\n",
    "with open(\"assets/keep_list.pickle\",\"wb\") as file:\n",
    "    pickle.dump(keep_list,file)\n",
    "with open(\"assets/drop_list.pickle\",\"wb\") as file:\n",
    "    pickle.dump(drop_list,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will feed this *drop_list* back into the preprocessing function to remove the non-descript words from the ingredient descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Ingredients in our Pantry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:57:49.304125Z",
     "start_time": "2018-04-08T21:55:59.038613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27638/27638 [01:49<00:00, 252.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27638\n"
     ]
    }
   ],
   "source": [
    "# re-process ingredient list, this time removing the non-descript words identified above\n",
    "# getting data ready to identify similiarity with our pantry items\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(short_recipes['ingredientLines'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recipes_drops = Parallel(n_jobs=num_cores)(delayed(multi_process_ingredients)(i,join=0,\n",
    "                                                                                  nondescript=1,\n",
    "                                                                                  drop_words=drop_list\n",
    "                                                                                 )\n",
    "                                                                            for i in inputs)\n",
    "print(len(recipes_drops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pantry Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I inventoried my kitchen to build a baseline set of ingredients we can expect to find in a kitchen.\n",
    "\n",
    "These ingredients are matched to the master list of ingredients, using fuzzy matching, and matches are dropped out of the ingredient list to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T21:58:29.465638Z",
     "start_time": "2018-04-08T21:58:29.449962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pantry = ['oregano','garlic powder','ground cumin','onion powder','ground mustard','hot hungarian paprika',\n",
    "          'mexican oregano','smoked paprika','dill weed','ground turmeric','ground ginger','ground cloves',\n",
    "         'cumin seed','cayenne pepper','chili powder','ground thyme','celery seed','curry powder',\n",
    "          'ground white pepper','paprika','ground nutmeg','old bay','maple syrup','thyme leaves',\n",
    "          'ground black pepper','black pepper','black peppercorns','crushed red pepper flakes','whole oregano',\n",
    "         'minced onion','fennel seed','cinnamon','dried basil','anise seed','bay leaves','bay leaf',\n",
    "          'ancho chili powder','ground cloves','coriander','vanilla extract','italian seasoning',\n",
    "          'apple cider vinegar','honey','corn starch','balsamic vinegar','bread crumbs','white wine vinegar',\n",
    "         'soy sauce','ketchup','tomato ketchup','red wine vinegar','vegatable oil','canola oil','sherry',\n",
    "          'baking powder','baking soda','molasses','peanut butter','olive oil','extra virgin olive oil','salt',\n",
    "          'sea salt','kosher salt','white vinegar','egg','eggs','egg whites','egg yolk','brown sugar','sugar',\n",
    "          'flour','evoo','butter','salt pepper','garlic','garlic clove']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pantry Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:00:18.176718Z",
     "start_time": "2018-04-08T21:58:48.260322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32983\n"
     ]
    }
   ],
   "source": [
    "# this eliminates ingredients that have been wholly reduced to blanks\n",
    "test = [[[ingredient for \n",
    "                   ingredient in recipe if ingredient != ''] \n",
    "                  for recipe in item] \n",
    "                 for item in recipes_drops]\n",
    "\n",
    "# we're going to take all the ingredients from every recipe and string them together\n",
    "# then take the set of that to find every unique ingredient\n",
    "\n",
    "ingredient_master = []\n",
    "for items in test:\n",
    "    for recipe in items:\n",
    "        ingredient_master = list(set(ingredient_master + recipe))\n",
    "print(len(ingredient_master))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:00:24.919134Z",
     "start_time": "2018-04-08T22:00:24.883431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the ingredient_master list, we eliminate ingredients that bear substantial similiarity to our pantry items\n",
    "# because these ingredients are IN our pantry, they are not essential for determining overall recipe similiarity\n",
    "# in fact, it gives us more degrees of freedom to find a match by increasing the range of possible flavor profiles\n",
    "# of a related recipe -- because we go into the pantry and pull out different spices other than those in our target\n",
    "# recipe\n",
    "# this will fuzzy matching (ratio)\n",
    "\n",
    "def match_pantry(ingredient_list,pantry_items=pantry,n_jobs=0):\n",
    "    if n_jobs == 1:\n",
    "        if ingredient_list in pantry_items:\n",
    "            return ingredient_list\n",
    "        else:\n",
    "            for item in pantry_items:\n",
    "                if fuzz.ratio(item,ingredient_list) > 70:\n",
    "                    return ingredient_list\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        pantry_matches = []\n",
    "\n",
    "        for ingredient in ingredient_list:\n",
    "            if ingredient in pantry_items:\n",
    "                pantry_matches.append(ingredient)\n",
    "            else:\n",
    "                for item in pantry_items:\n",
    "                    if fuzz.ratio(item,ingredient) > 70:\n",
    "                        pantry_matches.append(ingredient)\n",
    "                        break\n",
    "        return pantry_matches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:00:34.637252Z",
     "start_time": "2018-04-08T22:00:28.017891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32983/32983 [00:06<00:00, 5322.38it/s]\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(ingredient_master)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pantry_matches = Parallel(n_jobs=num_cores)(delayed(match_pantry)(i,pantry,n_jobs=1) for i in inputs)\n",
    "    \n",
    "pantry_matches = [match for match in pantry_matches if match != None]\n",
    "\n",
    "with open(\"assets/pantry_matches.pickle\",\"wb\") as file:\n",
    "    pickle.dump(pantry_matches,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Ingredient Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing all the above preprocessing steps on the ingredients, we still need to reduce the dimensionality of the ingredients that describe the recipes in the cookbook.\n",
    "\n",
    "My solution is to take the list of each unique ingredient, CountVectorize them, and feed them into an agglomerative clustering algorithm. \n",
    "\n",
    "With our cluster assignments, we will replace ingredients to be represented by the cluster that they belong to. Our recipes will now be able to be represented as a vector of clusters instead a vector of ingredients.\n",
    "\n",
    "The dimensionality of ingredient will have then been reduced, and we can move into the recipe recommender and measuring the similiarity between recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:02:41.182758Z",
     "start_time": "2018-04-08T22:00:47.612245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27638/27638 [01:52<00:00, 245.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# re-process ingredient list, this time removing the non-descript words and pantry items as identified above\n",
    "# getting data ready for clustering\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(short_recipes['ingredientLines'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cookbook = Parallel(n_jobs=num_cores)(delayed(multi_process_ingredients)(i,join=0,\n",
    "                                                                                  nondescript=1,\n",
    "                                                                                  drop_words=drop_list,\n",
    "                                                                                  pantry=1,\n",
    "                                                                                  pantry_items=pantry_matches\n",
    "                                                                                 )\n",
    "                                                                            for i in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:04:17.206890Z",
     "start_time": "2018-04-08T22:02:42.861735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31266\n"
     ]
    }
   ],
   "source": [
    "# this eliminates ingredients that have been wholly reduced to blanks\n",
    "test = [[[ingredient for \n",
    "                   ingredient in recipe if ingredient != ''] \n",
    "                  for recipe in item] \n",
    "                 for item in cookbook]\n",
    "\n",
    "# we're going to take all the ingredients from every recipe and string them together\n",
    "# then take the set of that to find every unique ingredient\n",
    "ingredient_master = []\n",
    "for items in test:\n",
    "    for recipe in items:\n",
    "        ingredient_master = list(set(ingredient_master + recipe))\n",
    "print(len(ingredient_master))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T22:12:08.809377Z",
     "start_time": "2018-04-08T22:12:08.185245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31266, 7265)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_master_cvector = CountVectorizer(strip_accents=ascii)\n",
    "ingredient_master_cvectordata = ingredient_master_cvector.fit_transform(ingredient_master)\n",
    "\n",
    "ingredient_master_cvector_dense  = pd.DataFrame(ingredient_master_cvectordata.todense(),\n",
    "             columns=ingredient_master_cvector.get_feature_names())\n",
    "\n",
    "ingredient_master_cvector_dense.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering of Vectorized Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dendogram(df):\n",
    "    \n",
    "    # Data preparation:\n",
    "    X = df.values\n",
    "    Z = linkage(X, 'ward')\n",
    "    \n",
    "    # Plotting:\n",
    "    plt.title('Dendrogram')\n",
    "    plt.xlabel('Index Numbers')\n",
    "    plt.ylabel('Distance')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,  \n",
    "        leaf_font_size=8.,\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_dendogram(ingredient_master_cvector_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "def plot_dist_thresh(max_dist=200):\n",
    "    # max_dist = 200 # Pairwise distance.\n",
    "    plot_dendogram(lang)\n",
    "    clusters = fcluster(Z, max_dist, criterion='distance')\n",
    "    \n",
    "    print(\"Clusters represented at distance: \", set(clusters))\n",
    "    \n",
    "    # Complete color maps from Matplotlib.\n",
    "    \n",
    "    # Plotting.\n",
    "    # Add a legend with some customizations.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    ax[0].scatter(lang.index, X[:,5], c=clusters, cmap=cm.jet, s=40)\n",
    "    ax[0].set_title(\"Max Dist: %d\" % max_dist)\n",
    "    plt.legend(clusters, loc='upper right', shadow=True, scatterpoints=1)\n",
    "    ax[0].legend(['c{}'.format(i) for i in range(len(clusters))], loc=2, bbox_to_anchor=(1.05, 1),\n",
    "                 borderaxespad=0., fontsize=11)\n",
    "        \n",
    "    t = (0, max_dist)\n",
    "    ax[1].plot((0, 200), (max_dist, max_dist), 'r--')\n",
    "    ax[1].set_title('Dendrogram')\n",
    "    ax[1].set_xlabel('Index Numbers')\n",
    "    ax[1].set_ylabel('Distance')\n",
    "    R = dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,  \n",
    "        leaf_font_size=8.,\n",
    "        ax=ax[1]\n",
    "        #link_color_func=lambda color: cmaps['Miscellaneous'],\n",
    "    )\n",
    "    return None\n",
    "    \n",
    "def plot_wrapper(max_dist):\n",
    "    plot_dist_thresh(max_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent Recipes as Vectors of Clusters, Instead of Vectors of Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data for Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cookbook_df = pd.DataFrame(cookbook)\n",
    "cookbook_df.rename(columns={0:'cookbook'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop out ingredients that have been reduced to blanks after stop words\n",
    "\n",
    "cookbook_pipe = [[[ingredient for \n",
    "                   ingredient in recipe if ingredient != ''] \n",
    "                  for recipe in item] \n",
    "                 for item in cookbook]\n",
    "\n",
    "# collapse list of list of ingredients into \n",
    "# pipe-separated list of ingredients to feed to tokenizer\n",
    "\n",
    "cookbook_pipe = [[\"|\".join(ingredient) for \n",
    "                        ingredient in recipe] \n",
    "                       for recipe in cookbook]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_center_rows(df):\n",
    "    return (df.T - df.mean(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes_mc = mean_center_rows(ingredient_cvector_dense)\n",
    "\n",
    "# check for nulls\n",
    "print('nulls: {}'.format(recipes_mc.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_matrix = cosine_similarity(recipes_mc)\n",
    "recipe_sim = pd.DataFrame(sim_matrix, columns=recipes_mc.index, index=recipes_mc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(recipe_sim, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
